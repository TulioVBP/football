{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra.utils import to_absolute_path as abspath\n",
    "import os\n",
    "\n",
    "path = abspath(\"../data/to_predict/\")\n",
    "os.path.isdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "Path(\"data/to_predict\").is_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "url = \"https://understat.com/league/EPL\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "div = soup.find(\"div\",{\"class\": \"calendar-container\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripts = soup.find_all(\"script\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import json\n",
    "from pandas import json_normalize\n",
    "\n",
    "encoded_string = str(scripts[1])\n",
    "encoded_string = encoded_string.split(\n",
    "    \"JSON.parse('\", 1\n",
    ")[-1]\n",
    "# encoded_string = encoded_string.rsplit(\"=\",1)[0]\n",
    "encoded_string = encoded_string.rsplit(\"');\", 1)[0]\n",
    "# Have it ignore the escape characters so it can decode the ascii\n",
    "# and be able to use json.loads\n",
    "jsonStr = codecs.getdecoder(\"unicode-escape\")(\n",
    "    encoded_string\n",
    ")[0]\n",
    "jsonObj = json.loads(jsonStr.split(\"]\")[0]+\"]\")\n",
    "df = json_normalize(jsonObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScraperFutureMatches:\n",
    "    def __init__(\n",
    "        self, \n",
    "        leagues = [\"EPL\", \"La liga\", \"Bundesliga\", \"Serie A\", \"Ligue 1\", \"RFPL\"],\n",
    "        parent_folder = \"../data/raw/future_matches\"\n",
    "    ):\n",
    "        self.leagues = leagues\n",
    "        self.parent_folder = Path(parent_folder)\n",
    "\n",
    "    def loop_scrape(\n",
    "        self\n",
    "    ):\n",
    "        # Step 0 - Create parent dir if there isn't one\n",
    "        if not self.parent_folder.exists():\n",
    "            self.parent_folder.mkdir()\n",
    "        \n",
    "        for league in self.leagues:\n",
    "            url = (\n",
    "                    \"https://understat.com/league/\"\n",
    "                    + league\n",
    "                )\n",
    "            response = requests.get(url)\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "            scripts = soup.find_all(\"script\")\n",
    "            for script in scripts:\n",
    "                if \"var datesData\" in str(script):\n",
    "                    encoded_string = str(script)\n",
    "                    encoded_string = encoded_string.split(\n",
    "                        \"JSON.parse('\", 1\n",
    "                    )[-1]\n",
    "                    # encoded_string = encoded_string.rsplit(\"=\",1)[0]\n",
    "                    encoded_string = encoded_string.rsplit(\"');\", 1)[0]\n",
    "                    # Have it ignore the escape characters so it can decode the ascii\n",
    "                    # and be able to use json.loads\n",
    "                    jsonStr = codecs.getdecoder(\"unicode-escape\")(\n",
    "                        encoded_string\n",
    "                    )[0]\n",
    "                    jsonObj = json.loads(jsonStr.split(\"]\")[0]+\"]\")\n",
    "                    df = json_normalize(jsonObj)\n",
    "                    break\n",
    "            # Step - Save the file\n",
    "            df.drop(df[df[\"isResult\"] == True].index,inplace=True)\n",
    "            df[\"league\"] = league\n",
    "            df.to_csv(self.parent_folder.joinpath(league + \".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "scraper = ScraperFutureMatches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper.loop_scrape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
