{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bffbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "import codecs\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "import os\n",
    "from pathlib import Path\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe40fbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 - Obtain website soup for the given league and season\n",
    "url = 'https://understat.com/match/4406'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8349b2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - Identify the players data\n",
    "roster_home = soup.find(\"div\", class_ = 'roster roster-home'); roster_home\n",
    "roster_away = soup.find(\"div\", class_ = 'roster roster-away')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa0c66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rhp = roster_home.find_all('label', class_='player'); rhp\n",
    "rap = roster_away.find_all('label',class_='player')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cac1780",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rhp[0])\n",
    "print(rhp[0].find('span',class_ = 'player-name').text)\n",
    "print(rhp[0]['data-id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bc6cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = ['matchId','date','homeTeam','awayTeam','homeScore','awayScore','playerId','playerName','playerPosition','playerTime','playerSide']\n",
    "df_squad = pd.DataFrame(columns = schema)\n",
    "\n",
    "for matchId in range(1): # Guessing a maximum of 20.000 matches\n",
    "    header = soup.find('div', class_ = 'header-wrapper') # Extracting the header of the page\n",
    "    teams  = header.find_all('a',class_ = not 'link-icon'); # Extracting the name of the teams\n",
    "    score = [header.find('span').text.split(' - ')[0][-1], header.find('span').text.split(' - ')[1][0]]\n",
    "    breadcrumb = soup.find('ul',class_ = 'breadcrumb'); # Extracting date\n",
    "    date = breadcrumb.find_all('li')[-1].text\n",
    "    for player_data in rhp:\n",
    "        temp = {}\n",
    "        temp['matchId'] = matchId\n",
    "        temp['date'] = date\n",
    "        temp['homeTeam'] = teams[0].text\n",
    "        temp['awayTeam'] = teams[1].text\n",
    "        temp['homeScore'] = score[0]\n",
    "        temp['awayScore'] = score[1]\n",
    "        temp['playerId'] = player_data['data-id']\n",
    "        temp['playerName'] = player_data.find('span',class_ = 'player-name').text\n",
    "        temp['playerPosition'] = player_data.find('span',class_ = 'player-position').text\n",
    "        temp['playerTime'] = player_data.find('span',class_ = 'player-time').text\n",
    "        temp['playerSide'] = 'h'\n",
    "        df_squad = df_squad.append(pd.DataFrame(temp,index = [0]),ignore_index = True)\n",
    "    for player_data in rap:\n",
    "        temp = {}\n",
    "        temp['matchId'] = matchId\n",
    "        temp['date'] = date\n",
    "        temp['homeTeam'] = teams[0].text\n",
    "        temp['awayTeam'] = teams[1].text\n",
    "        temp['homeScore'] = score[0]\n",
    "        temp['awayScore'] = score[1]\n",
    "        temp['playerId'] = player_data['data-id']\n",
    "        temp['playerName'] = player_data.find('span',class_ = 'player-name').text\n",
    "        temp['playerPosition'] = player_data.find('span',class_ = 'player-position').text\n",
    "        temp['playerTime'] = player_data.find('span',class_ = 'player-time').text\n",
    "        temp['playerSide'] = 'a'\n",
    "        df_squad = df_squad.append(pd.DataFrame(temp,index = [0]),ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69a7b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd4a11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class match:\n",
    "    def __init__(id_, rhp, rap):\n",
    "        matchId = id_\n",
    "        df_posconf = pd.read_excel('config/positions_config.xlsx') # Load the positions config file\n",
    "        macropositions = df_posconf['Macro position'].unique().tolist();\n",
    "        \n",
    "\n",
    "    def map_position(pos):\n",
    "        # trim R and L from the end\n",
    "        if pos[-1] == 'R':\n",
    "            pos = pos.rsplit('R',1)[0]\n",
    "        elif pos[-1] == 'L':\n",
    "            pos = pos.rsplit('L',1)[0]\n",
    "        # Define macro pos\n",
    "        try:\n",
    "            macro = df_posconf.loc[df_posconf['Abbreviation'] == pos,'Macro position']\n",
    "        except KeyError:\n",
    "            macro = df_posconf.loc[df_posconf['Abbreviation'] =='Default','Macro position']\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bcd41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'RAB'.rsplit('R',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1178739",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = soup.find('div', class_ = 'header-wrapper'); #print(header)\n",
    "squads  = header.find_all('a',class_ = not 'link-icon');\n",
    "breadcrumb = soup.find('ul',class_ = 'breadcrumb'); #print(breadcrumb)\n",
    "print('Date: ', breadcrumb.find_all('li')[-1].text)\n",
    "print('Home team: ', squads[0].text)\n",
    "print('Away team: ', squads[1].text)\n",
    "print('Result: ',header.find('span').text.split(' - ')[0][-1],'-',header.find('span').text.split(' - ')[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65f18a3",
   "metadata": {},
   "source": [
    "## Explore table data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb34b6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "scripts = soup.find_all('script'); scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d615925",
   "metadata": {},
   "outputs": [],
   "source": [
    "for script in scripts:\n",
    "    if 'var rostersData' in str(script):\n",
    "        # I store that text, then trim off the string on the ends so that \n",
    "        # it's in a valid json format\n",
    "        encoded_string = str(script)\n",
    "        encoded_string  = encoded_string.split(\"JSON.parse('\",1)[-1]\n",
    "        #encoded_string = encoded_string.rsplit(\"=\",1)[0]\n",
    "        encoded_string = encoded_string.rsplit(\"');\",1)[0]\n",
    "        # Have it ignore the escape characters so it can decode the ascii \n",
    "        # and be able to use json.loads\n",
    "        jsonStr = codecs.getdecoder('unicode-escape')(encoded_string)[0]\n",
    "        jsonObj = json.loads(jsonStr)\n",
    "        # Due to the many levels, we create a list of dicts to be processed by json_normalize\n",
    "        jsonObjH = [jsonObj['h'][ii] for ii in list(jsonObj['h'])]\n",
    "        jsonObjA = [jsonObj['a'][ii] for ii in list(jsonObj['a'])]\n",
    "        db_h = json_normalize(jsonObjH).set_index('id')\n",
    "        db_a = json_normalize(jsonObjA).set_index('id')\n",
    "        db = db_h.append(db_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36302ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d790b600",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonObj['a']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582d9c8d",
   "metadata": {},
   "source": [
    "# Alternative solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562fe2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for matchId in range(20000): # Guessing a maximum of 20.000 matches\n",
    "    url = 'https://understat.com/match/'+str(matchId)\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        print('OK for ',matchId)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        header = soup.find('div', class_ = 'header-wrapper') # Extracting the header of the page\n",
    "        score = [header.find('span').text.split(' - ')[0][-1], header.find('span').text.split(' - ')[1][0]]\n",
    "        breadcrumb = soup.find('ul',class_ = 'breadcrumb'); # Extracting date\n",
    "        date = breadcrumb.find_all('li')[-1].text\n",
    "        scripts = soup.find_all('script'); # Scripts with data\n",
    "        for script in scripts:\n",
    "            if 'var rostersData' in str(script):\n",
    "                # I store that text, then trim off the string on the ends so that \n",
    "                # it's in a valid json format\n",
    "                encoded_string = str(script)\n",
    "                encoded_string  = encoded_string.split(\"JSON.parse('\",1)[-1]\n",
    "                #encoded_string = encoded_string.rsplit(\"=\",1)[0]\n",
    "                encoded_string = encoded_string.rsplit(\"');\",1)[0]\n",
    "                # Have it ignore the escape characters so it can decode the ascii \n",
    "                # and be able to use json.loads\n",
    "                jsonStr = codecs.getdecoder('unicode-escape')(encoded_string)[0]\n",
    "                jsonObj = json.loads(jsonStr)\n",
    "                # Due to the many levels, we create a list of dicts to be processed by json_normalize\n",
    "                jsonObjH = [jsonObj['h'][ii] for ii in list(jsonObj['h'])]\n",
    "                jsonObjA = [jsonObj['a'][ii] for ii in list(jsonObj['a'])]\n",
    "                db_h = json_normalize(jsonObjH).set_index('id')\n",
    "                db_a = json_normalize(jsonObjA).set_index('id')\n",
    "                db = db_h.append(db_a)\n",
    "                db['matchId'] = matchId\n",
    "                db['date'] = date\n",
    "                db['homeScore'] = score[0]\n",
    "                db['awayScore'] = score[1]\n",
    "                break\n",
    "        df = df.append(db)\n",
    "    else:\n",
    "        print('Not OK for ',matchId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f85d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb683790",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://understat.com/match/4406'\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae68c79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ccdd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path('test.csv').exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ecac28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddafff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataPreprocessing import DataPreprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad656ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataStream = DataPreprocessing(update = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284d0ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataPreprocessing import DataPreprocessing\n",
    "dataStream = DataPreprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a1a86c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
